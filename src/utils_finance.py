# Importing necessary librarys
import pandas as pd
import numpy as np
#import pyarrow.parquet as pq  # For working with parquet files
import re
import seaborn as sns
# Import System libraries
import sys
import os

# Path to the neighboring 'data' folder in the local repository
data_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))

def reduce_multiple_spaces_and_newlines(df):
    """
    Function to replace multiple spaces and new lines with a single space in string columns.
    """
    def clean_text(text):
        if isinstance(text, str):
            text = re.sub(r'\s+', ' ', text)
            return text.replace('\n', ' ').strip()
        return text
    
    for col in df.select_dtypes(include=['object', 'string']):
        df[col] = df[col].apply(clean_text)
    return df

def basic_analysis(df):
    """
    Performs basic financial analysis on the DataFrame.
    """
    df['Betrag (‚Ç¨)'] = pd.to_numeric(df['Betrag (‚Ç¨)'], errors='coerce')
    income = df[df['Betrag (‚Ç¨)'] > 0]['Betrag (‚Ç¨)'].sum()
    expenses = df[df['Betrag (‚Ç¨)'] < 0]['Betrag (‚Ç¨)'].sum()

    df['Buchungsdatum'] = pd.to_datetime(df['Buchungsdatum'])
    df['month'] = df['Buchungsdatum'].dt.to_period('M')
    monthly_savings = df.groupby('month')['Betrag (‚Ç¨)'].sum()

    largest_expense = df[df['Betrag (‚Ç¨)'] < 0].nsmallest(1, 'Betrag (‚Ç¨)')
    largest_income = df[df['Betrag (‚Ç¨)'] > 0].nlargest(1, 'Betrag (‚Ç¨)')

    most_frequent_income_source = df[df['Betrag (‚Ç¨)'] > 0]['Zahlungspflichtige*r'].value_counts().idxmax()
    most_frequent_expense_target = df[df['Betrag (‚Ç¨)'] < 0]['Zahlungsempf√§nger*in'].value_counts().idxmax()

    print(f"Total Income: ‚Ç¨{income:.2f}")
    print(f"Total Expenses: ‚Ç¨{expenses:.2f}")
    print("Monthly Savings:")
    print(monthly_savings)
    print("\nLargest Expense:")
    print(largest_expense[['Buchungsdatum', 'Zahlungsempf√§nger*in', 'Betrag (‚Ç¨)']])
    print("\nLargest Income:")
    print(largest_income[['Buchungsdatum', 'Zahlungspflichtige*r', 'Betrag (‚Ç¨)']])
    print(f"\nMost frequent income source: {most_frequent_income_source}")
    print(f"Most frequent outgoing target: {most_frequent_expense_target}")

def analyze_by_category(df):
    """
    Groups and analyzes transactions by category.
    """
    category_summary = df.groupby('Umsatztyp')['Betrag (‚Ç¨)'].sum()
    print("\nTotal by Category:")
    print(category_summary)

def income_expense_trend(df):
    """
    Creates a time series analysis of income and expenses.
    """
    df['Buchungsdatum'] = pd.to_datetime(df['Buchungsdatum'], errors='coerce')
    df = df.dropna(subset=['Buchungsdatum'])
    df['week'] = df['Buchungsdatum'].dt.to_period('W').apply(lambda r: r.start_time)
    trend = df.groupby('week')['Betrag (‚Ç¨)'].sum()

    plt.figure(figsize=(12, 6))
    trend.plot(kind='line', title='Income and Expense Trend Over Time (Weekly)', 
              ylabel='Amount (‚Ç¨)', xlabel='Week')
    plt.xticks(rotation=45)
    plt.grid()
    plt.tight_layout()
    plt.show()

def average_monthly_stats(df):
    """
    Calculates average monthly income and expenses.
    """
    df['Buchungsdatum'] = pd.to_datetime(df['Buchungsdatum'], errors='coerce')
    df['month'] = df['Buchungsdatum'].dt.to_period('M')
    monthly_income = df[df['Betrag (‚Ç¨)'] > 0].groupby('month')['Betrag (‚Ç¨)'].sum().mean()
    monthly_expenses = df[df['Betrag (‚Ç¨)'] < 0].groupby('month')['Betrag (‚Ç¨)'].sum().mean()
    
    print(f"Average Monthly Income: ‚Ç¨{monthly_income:.2f}")
    print(f"Average Monthly Expenses: ‚Ç¨{monthly_expenses:.2f}")

def detect_recurring_transactions(df):
    """
    Identifies recurring transactions based on similar amounts and descriptions.
    """
    recurring = df[df.duplicated(['Zahlungsempf√§nger*in', 'Betrag (‚Ç¨)'], keep=False)]
    recurring_summary = recurring.groupby(['Zahlungsempf√§nger*in', 'Betrag (‚Ç¨)']).size().reset_index(name='Count')
    recurring_summary = recurring_summary.sort_values(by='Count', ascending=False)
    
    return recurring, recurring_summary

def plot_recurring_summary(recurring_summary):
    """
    Plots a summary of recurring transactions.
    """
    plt.figure(figsize=(10, 6))
    sns.barplot(data=recurring_summary.head(10), x='Count', y='Zahlungsempf√§nger*in', hue='Betrag (‚Ç¨)')
    plt.title('Top 10 Recurring Transactions')
    plt.xlabel('Count')
    plt.ylabel('Recipient')
    plt.legend(title='Amount (‚Ç¨)')
    plt.show()

def expense_income_ratio(df):
    """
    Calculates the expense-to-income ratio per month.
    """
    df['month'] = df['Buchungsdatum'].dt.to_period('M')
    income = df[df['Betrag (‚Ç¨)'] > 0].groupby('month')['Betrag (‚Ç¨)'].sum()
    expenses = df[df['Betrag (‚Ç¨)'] < 0].groupby('month')['Betrag (‚Ç¨)'].sum().abs()
    ratio = (expenses / income).fillna(0)
    print("\nExpense to Income Ratio per Month:")
    print(ratio)

def expenses_by_recipient(df):
    """
    Provides a breakdown of expenses by recipient.
    """
    expense_summary = df[df['Betrag (‚Ç¨)'] < 0].groupby('Zahlungsempf√§nger*in')['Betrag (‚Ç¨)'].sum()
    print("\nExpenses by Recipient:")
    print(expense_summary.sort_values())

def detect_outliers(df, threshold=3):
    """
    Identifies unusual transactions using standard deviation.
    """
    mean = df['Betrag (‚Ç¨)'].mean()
    std_dev = df['Betrag (‚Ç¨)'].std()
    outliers = df[(df['Betrag (‚Ç¨)'] < (mean - threshold * std_dev)) | 
                  (df['Betrag (‚Ç¨)'] > (mean + threshold * std_dev))]
    print("\nOutliers:")
    print(outliers[['Buchungsdatum', 'Betrag (‚Ç¨)', 'Verwendungszweck']])

def savings_percentage(df):
    """
    Calculates and visualizes monthly savings percentage.
    """
    df['Buchungsdatum'] = pd.to_datetime(df['Buchungsdatum'])
    df['month'] = df['Buchungsdatum'].dt.to_period('M')
    income = df[df['Betrag (‚Ç¨)'] > 0].groupby('month')['Betrag (‚Ç¨)'].sum()
    expenses = df[df['Betrag (‚Ç¨)'] < 0].groupby('month')['Betrag (‚Ç¨)'].sum().abs()
    savings_percent = ((income - expenses) / income * 100).fillna(0)

    plt.figure(figsize=(12, 6))
    sns.lineplot(x=savings_percent.index.astype(str), y=savings_percent.values, marker='o')
    plt.title('Monthly Savings Percentage')
    plt.xlabel('Month')
    plt.ylabel('Savings Percentage (%)')
    plt.xticks(rotation=45)
    plt.grid()
    plt.axhline(0, color='red', linestyle='--')
    plt.tight_layout()
    plt.show()

def cash_flow_volatility(df):
    """
    Calculates and visualizes cash flow stability.
    """
    df['Buchungsdatum'] = pd.to_datetime(df['Buchungsdatum'])
    df['month'] = df['Buchungsdatum'].dt.to_period('M')
    monthly_balance = df.groupby('month')['Betrag (‚Ç¨)'].sum()
    volatility = monthly_balance.std() / monthly_balance.mean()

    plt.figure(figsize=(12, 6))
    sns.lineplot(x=monthly_balance.index.astype(str), y=monthly_balance.values, marker='o')
    plt.title('Monthly Cash Flow')
    plt.xlabel('Month')
    plt.ylabel('Cash Flow (‚Ç¨)')
    plt.xticks(rotation=45)
    plt.axhline(0, color='red', linestyle='--', label='Zero Line')
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.show()

def income_by_source(df):
    """
    Analyzes and visualizes income sources.
    """
    df['Betrag (‚Ç¨)'] = pd.to_numeric(df['Betrag (‚Ç¨)'], errors='coerce')
    income_data = df[df['Betrag (‚Ç¨)'] > 0]
    income_summary = income_data.groupby('Zahlungspflichtige*r')['Betrag (‚Ç¨)'].sum()

    plt.figure(figsize=(12, 6))
    sns.barplot(x=income_summary.index, y=income_summary.values, palette='viridis')
    plt.title('Total Income by Source')
    plt.xlabel('Income Source')
    plt.ylabel('Total Income (‚Ç¨)')
    plt.xticks(rotation=45, ha='right')
    plt.grid(axis='y')
    plt.tight_layout()
    plt.show()

def fix_euro_amounts(df, column_name='Betrag (‚Ç¨)'):
    """
    Fixes Euro amount formatting in the DataFrame.
    """
    try:
        df[column_name] = df[column_name].astype(str)
        df[column_name] = df[column_name].str.replace('.', '', regex=False)
        df[column_name] = df[column_name].str.replace(',', '.', regex=False)
        df[column_name] = df[column_name].astype(float)
        return df
    except KeyError:
        print(f"Column '{column_name}' not found. Available columns:", df.columns.tolist())
        return df
    except Exception as e:
        print(f"Error processing column '{column_name}':", str(e))
        return df

def inspect_data(df):
    """
    Function to perform an initial data inspection on a given DataFrame.

    Parameters:
    df (pd.DataFrame): The DataFrame to inspect.

    Returns:
    None
    """
    print("="*40)
    print("üöÄ Basic Data Overview")
    print("="*40)

    # Print the shape of the DataFrame (rows, columns)
    print(f"üóÇ Shape of the DataFrame: {df.shape[0]} rows, {df.shape[1]} columns")

    # Display the first 5 rows of the dataset
    print("\nüîç First 5 rows of the DataFrame:")
    print(df.head(5))

    # Get information about data types, missing values, and memory usage
    print("\nüìä DataFrame Information:")
    df.info()

    # Show basic statistics for numeric columns
    print("\nüìà Summary Statistics of Numeric Columns:")
    print(df.describe())

    # Count missing values and display
    print("\n‚ùì Missing Values Overview:")
    missing_df = count_missing_values(df)
    print(missing_df)

    # Print unique values for categorical and object columns
    print("\nüîë Unique Values in Categorical/Object Columns:")
    print_unique_values(df)

def count_missing_values(df, columns):
    """
    Counts occurrences of "nan", "None", np.nan, None, pd.NA, and '' (empty string) in the specified columns of a DataFrame.
    Also includes the data type of each column.

    Parameters:
    df (pd.DataFrame): The DataFrame containing the columns to check.
    columns (list): List of column names (as strings) to check for missing values.

    Returns:
    pd.DataFrame: A DataFrame summarizing the count of missing value types per column.
    """
    results = []
    for col in columns:
        if pd.api.types.is_categorical_dtype(df[col]):
            # If the column is categorical, convert it to object to capture all kinds of missing values
            col_data = df[col].astype(object)
        else:
            col_data = df[col]

        # Total missing (both np.nan, pd.NA, None)
        total_missing = col_data.isna().sum()

        # Count only np.nan by checking where it's actually a float and is NaN
        np_nan_count = (col_data.apply(lambda x: isinstance(x, float) and pd.isna(x))).sum()

        # Count actual `None` values (None treated as an object)
        none_object_count = (col_data.apply(lambda x: x is None)).sum()

        # pd.NA count: in categorical columns, we check if the missing value type is distinct from np.nan
        if pd.api.types.is_categorical_dtype(df[col]):
            pd_na_count = col_data.isna().sum() - none_object_count - np_nan_count
        else:
            pd_na_count = total_missing - np_nan_count

        counts = {
            'Column': col,
            'Data Type': df[col].dtype,
            'nan (string)': (col_data == 'nan').sum(),
            'None (string)': (col_data == 'None').sum(),
            'np.nan': np_nan_count,
            'pd.NA': pd_na_count,
            'None (object)': none_object_count,
            'Empty string': (col_data == '').sum(),
        }
        results.append(counts)

    return pd.DataFrame(results)

def print_unique_values(df):
    """
    Function to print the number of unique values for categorical and object columns.

    Parameters:
    df (pd.DataFrame): The DataFrame to inspect.

    Returns:
    None
    """
    cat_obj_cols = df.select_dtypes(include=['category', 'object']).columns
    unique_counts = {}

    for col in cat_obj_cols:
        unique_counts[col] = df[col].nunique()

    if unique_counts:
        for col, count in unique_counts.items():
            print(f"Column '{col}' has {count} unique values")
    else:
        print("No categorical or object columns found.")